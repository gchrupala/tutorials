{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Recipes "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook contains a few recipes for loading and manipulating data. These techniques are useful \n",
      "in machine learning projects."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading mixed data\n",
      "\n",
      "Many datasets contain heterogeneous features: numeric, categorical, and text. However, the machine learning toolkit \n",
      "scikit learn expects its input to be numeric numpy arrays, and so there is some data manipulation that needs to be done.\n",
      "\n",
      "For this section you'll need these files:\n",
      "\n",
      "- [airline-train-features.csv](airline-train-features.csv)\n",
      "- [airline-test-features.csv](airline-test-features.csv)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most basic way of loading data from a CSV file is to use the csv module. It allows you to read rows one by one and\n",
      "store them in a list of dictionaries mapping feature names to feature values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import numpy\n",
      "def read_data(path):\n",
      "    rows = []\n",
      "    with open(path) as file:\n",
      "        reader = csv.DictReader(file)\n",
      "        for row in reader:\n",
      "            rows.append(row)\n",
      "        return rows"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = read_data(\"airline-train-features.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train[0:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[{'Id': '0',\n",
        "  'airline': 'Virgin America',\n",
        "  'location': '',\n",
        "  'retweet_count': '0',\n",
        "  'text': '@VirginAmerica What @dhepburn said.',\n",
        "  'timestamp': '2015-02-24 11:35:52 -0800',\n",
        "  'username': 'cairdin'},\n",
        " {'Id': '1',\n",
        "  'airline': 'Virgin America',\n",
        "  'location': '',\n",
        "  'retweet_count': '0',\n",
        "  'text': \"@VirginAmerica plus you've added commercials to the experience... tacky.\",\n",
        "  'timestamp': '2015-02-24 11:15:59 -0800',\n",
        "  'username': 'jnardino'},\n",
        " {'Id': '2',\n",
        "  'airline': 'Virgin America',\n",
        "  'location': 'Lets Play',\n",
        "  'retweet_count': '0',\n",
        "  'text': \"@VirginAmerica I didn't today... Must mean I need to take another trip!\",\n",
        "  'timestamp': '2015-02-24 11:15:48 -0800',\n",
        "  'username': 'yvonnalynn'}]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extracting features\n",
      "We will now define a pair of functions which will extract features from the data and stores them in a sparse array. The first function `features_fit_transform` should be used on training data. It returns the feature array, and also the information necessary \n",
      "to extract the same features from new data, such as your test set. This information is for example mappings from feature names to fueature indices, or the settings of the ngram extractor. This information is stored in a dictionary names `transformer` in the function definition below. \n",
      "\n",
      "Our second function `features_transform` should be used on development or test data. It takes the transformer dictionary as one input, and uses it to extract features from the given data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.sparse\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "def features_fit_transform(data):\n",
      "    \"\"\"Returns features extracted from data, and objects necessary to extract same \n",
      "    features from new data.data` is a list of dictionaries which map feature names to feature values.\n",
      "    \"\"\"\n",
      "    # In this example we will extract three sets of features:\n",
      "    # airline as a categorical\n",
      "    # location as a categorical \n",
      "    # retweet_count as a numerical\n",
      "    # text as character ngrams of size 1 to 3\n",
      "    # You can adapt this function to extract additional features\n",
      "    \n",
      "    transformer = {}\n",
      "    # First we convert categorical features to one-hot encoding using \n",
      "    #    http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer\n",
      "    categorical = [ { 'airline': row['airline'], 'location': row['location'] } \n",
      "                   for row in data ]\n",
      "    transformer['categorical'] = DictVectorizer(sparse=True)\n",
      "    X_categorical = transformer['categorical'].fit_transform(categorical)\n",
      "    \n",
      "    # Convert retweet_count to a numerical (int) 2D array\n",
      "    X_numerical = numpy.array([ [row['retweet_count']] for row in data ], dtype='int')\n",
      "\n",
      "    # Extract character ngrams from text using \n",
      "    #   http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
      "    # CountVectorizer also can extract word ngrams, and has various other options for extracting text features.\n",
      "    transformer['text'] = CountVectorizer(analyzer='char', ngram_range=(1,3))\n",
      "    X_text = transformer['text'].fit_transform([row['text'] for row in data ])\n",
      "    \n",
      "    # Finally we concatenate these array columnwise using the hstack function, \n",
      "    # so that all the features are in a single sparse array\n",
      "    X = scipy.sparse.hstack([X_categorical, X_numerical, X_text])\n",
      "    # Return the extracted features together with the transformer object.\n",
      "    return (X, transformer)\n",
      "\n",
      "    \n",
      "def features_transform(transformer, data):\n",
      "    \"\"\"Returns features extracted from data, reusing the given transformer object.\"\"\"\n",
      "    categorical = [ { 'airline': row['airline'], 'location': row['location'] } \n",
      "                   for row in data ]\n",
      "    X_categorical = transformer['categorical'].transform(categorical)\n",
      "    X_numerical = numpy.array([ [row['retweet_count']] for row in data ], dtype='int')\n",
      "    X_text = transformer['text'].transform([row['text'] for row in data ])\n",
      "    X = scipy.sparse.hstack([X_categorical, X_numerical, X_text])\n",
      "    return X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, T = features_fit_transform(data_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_test = read_data(\"airline-test-features.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = features_transform(T, data_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check the number of rows and columns in out data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(11640, 31476)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(3000, 31476)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of columns matches betweet train and test set: good."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading labels\n",
      "\n",
      "We'll define a function which reads the CSV file with the labels and returns a list of labels.\n",
      "\n",
      "You'll need the files:\n",
      "\n",
      "- [airline-train-label.csv](airline-train-label.csv)\n",
      "- [airline-test-label.csv](airline-test-label.csv)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_label(f):\n",
      "    result = []\n",
      "    with open(f) as file:\n",
      "        reader = csv.reader(file)\n",
      "        for row in reader:\n",
      "            # skip the Id field\n",
      "            result.append(row[1])\n",
      "    # The first item is the header, we'll skip it\n",
      "    return result[1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train = read_label(\"airline-train-label.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_train[0:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['neutral', 'positive', 'neutral']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_test = read_label(\"airline-test-label.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now ready to train a classifier on this data, and test its accuracy."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}