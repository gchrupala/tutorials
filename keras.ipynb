{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Getting started with Keras\n",
      "\n",
      "- https://github.com/fchollet/keras\n",
      "\n",
      "## Keras vs Theano\n",
      "\n",
      "- Keras is a wrapper on top of the Theano toolkit\n",
      "- Many standard models are very easy to define and use in Keras\n",
      "- More complicated models are often easier to implement directly in Theano\n",
      "  - or a more minimalist wrapper like https://github.com/gchrupala/funktional \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## GPU\n",
      "\n",
      "- It only makes sense to use NN models on very large datasets\n",
      "- In order to train them in reasonable time you need to run them on a GPU\n",
      "- Need access to GPU machines\n",
      "- Setting environment variable THEANO_FLAGS to appropriate value, and run with ``nohup`` via command line"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load some example data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "from sklearn.datasets import load_iris\n",
      "data = load_iris()\n",
      "# Inputs\n",
      "X = numpy.array(data.data[:,0:3], dtype='float32')\n",
      "# Output\n",
      "y = numpy.array(data.data[:,3], dtype='float32')\n",
      "\n",
      "print X.shape\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(150, 3)\n",
        "(150,)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train/test split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ix = numpy.arange(0,X.shape[0]) ; numpy.random.shuffle(ix)\n",
      "X_tr = X[ix[0:100]]\n",
      "X_te = X[ix[100:150]]\n",
      "y_tr = y[ix[0:100]]\n",
      "y_te=  y[ix[100:150]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define a regression model \n",
      "\n",
      "We'll use a fully connected feedforward network. This type of model is also known as a multi-layer perceptron (MLP)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD, Adam\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(16, input_dim=3, init='orthogonal', activation='tanh'))\n",
      "# model.add(Dropout(0.5)) # Dropout injects noise into the network and can sometimes help with overfitting\n",
      "model.add(Dense(16, init='orthogonal', activation='tanh'))\n",
      "# model.add(Dropout(0.5))\n",
      "model.add(Dense(1, init='orthogonal', activation='linear'))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compile and train the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
      "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
      "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
      "model.fit(X_tr, y_tr, nb_epoch=10, batch_size=1, verbose=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 1/10\n",
        "0s - loss: 0.5944\n",
        "Epoch 2/10\n",
        "0s - loss: 0.5290\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "0s - loss: 0.4740\n",
        "Epoch 4/10\n",
        "0s - loss: 0.4218\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "0s - loss: 0.3755\n",
        "Epoch 6/10\n",
        "0s - loss: 0.3309\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "0s - loss: 0.2912\n",
        "Epoch 8/10\n",
        "0s - loss: 0.2549\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "0s - loss: 0.2206\n",
        "Epoch 10/10\n",
        "0s - loss: 0.1905\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<keras.callbacks.History at 0x7f49e874e910>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Use trained model to generate predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = model.predict(X_te)\n",
      "y_pred.reshape((50,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([ 1.19890882,  1.42984228,  0.69870245,  0.80160465,  0.75701505,\n",
        "        1.62831585,  0.69345627,  0.74203651,  0.75856199,  0.62252899,\n",
        "        0.5893553 ,  0.86894343,  1.48320016,  1.24910882,  1.4470076 ,\n",
        "        0.68212735,  1.49129939,  1.38444947,  0.74601551,  0.71325265,\n",
        "        1.60607508,  1.38619382,  1.48739071,  0.75856199,  1.52834007,\n",
        "        1.44887858,  0.67392664,  1.51582167,  1.58478666,  1.37181369,\n",
        "        1.38571092,  0.67781653,  1.53252099,  1.56773541,  0.7414341 ,\n",
        "        1.49096407,  1.27561769,  0.74792634,  1.66690792,  0.76986645,\n",
        "        1.58242322,  1.41410044,  0.61177707,  1.48257519,  0.7911536 ,\n",
        "        1.58426184,  1.69612773,  0.71623715,  1.60739864,  1.6325195 ])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Compute Mean Absolute Error"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.mean(numpy.abs(y_pred - y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.72414622239175719"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use the ``evaluate`` method which will compute the specified loss function (MSE)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.evaluate(X_te, y_te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50/50 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.18938916640245679"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classification\n",
      "\n",
      "Prepare the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Inputs\n",
      "X = numpy.array(data.data, dtype='float32')\n",
      "# Output\n",
      "y = numpy.array(data.target, dtype='int32')\n",
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Indicator array for classes\n",
      "Y = numpy.zeros((150,3))\n",
      "for k in range(0,3):\n",
      "    Y[y==k,k]=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_tr = X[ix[0:100]]\n",
      "X_te = X[ix[100:150]]\n",
      "Y_tr = Y[ix[0:100]]\n",
      "Y_te = Y[ix[100:150]]\n",
      "y_te = y[ix[100:150]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Sequential()\n",
      "model.add(Dense(16, input_dim=4, init='orthogonal', activation='tanh'))\n",
      "# model.add(Dropout(0.5)) # Dropout injects noise into the network and can sometimes help with overfitting\n",
      "model.add(Dense(16, init='orthogonal', activation='tanh'))\n",
      "# model.add(Dropout(0.5))\n",
      "model.add(Dense(3, init='orthogonal', activation='softmax')) # We need to have as many units as classes, \n",
      "                                                             # and softmax activation\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
      "# For classification, the loss function should be categorical_crossentropy\n",
      "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
      "model.fit(X_tr, Y_tr, nb_epoch=10, batch_size=1, verbose=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 1/10\n",
        "0s - loss: 1.0301\n",
        "Epoch 2/10\n",
        "0s - loss: 0.6979\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "0s - loss: 0.5483\n",
        "Epoch 4/10\n",
        "0s - loss: 0.4732\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "0s - loss: 0.3984\n",
        "Epoch 6/10\n",
        "0s - loss: 0.3495\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "0s - loss: 0.2961\n",
        "Epoch 8/10\n",
        "0s - loss: 0.2595\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "0s - loss: 0.2247\n",
        "Epoch 10/10\n",
        "0s - loss: 0.2049\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<keras.callbacks.History at 0x7f49e14e0fd0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Output predicted class probabilities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.predict_proba(X_te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50/50 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([[  2.28763357e-01,   7.55860430e-01,   1.53762130e-02],\n",
        "       [  2.43751734e-02,   8.87224473e-01,   8.84003540e-02],\n",
        "       [  9.79403143e-01,   2.02742075e-02,   3.22649873e-04],\n",
        "       [  9.62143400e-01,   3.72990265e-02,   5.57573760e-04],\n",
        "       [  9.73030674e-01,   2.65625080e-02,   4.06817913e-04],\n",
        "       [  7.60514434e-04,   1.09988557e-01,   8.89250929e-01],\n",
        "       [  9.80162886e-01,   1.95268206e-02,   3.10293500e-04],\n",
        "       [  9.74256853e-01,   2.53415018e-02,   4.01645281e-04],\n",
        "       [  9.72789124e-01,   2.68138823e-02,   3.96993590e-04],\n",
        "       [  9.85355216e-01,   1.43908044e-02,   2.53979560e-04],\n",
        "       [  9.87115096e-01,   1.26659351e-02,   2.18969173e-04],\n",
        "       [  9.54780078e-01,   4.46113378e-02,   6.08583719e-04],\n",
        "       [  6.14536416e-03,   4.64001944e-01,   5.29852692e-01],\n",
        "       [  1.10202943e-01,   8.62644669e-01,   2.71523884e-02],\n",
        "       [  8.92982719e-03,   5.53397882e-01,   4.37672290e-01],\n",
        "       [  9.80843472e-01,   1.88349576e-02,   3.21570538e-04],\n",
        "       [  5.39156728e-03,   4.33774979e-01,   5.60833454e-01],\n",
        "       [  3.25704098e-02,   8.96602527e-01,   7.08270633e-02],\n",
        "       [  9.72575649e-01,   2.69837820e-02,   4.40569458e-04],\n",
        "       [  9.77948654e-01,   2.17099206e-02,   3.41425163e-04],\n",
        "       [  2.89353551e-03,   3.39154833e-01,   6.57951632e-01],\n",
        "       [  3.48341845e-02,   9.11232344e-01,   5.39334720e-02],\n",
        "       [  6.43019270e-03,   4.70486653e-01,   5.23083154e-01],\n",
        "       [  9.72789124e-01,   2.68138823e-02,   3.96993590e-04],\n",
        "       [  3.17590728e-03,   2.98430650e-01,   6.98393442e-01],\n",
        "       [  1.85604481e-02,   8.32139823e-01,   1.49299729e-01],\n",
        "       [  9.81810291e-01,   1.78831064e-02,   3.06602712e-04],\n",
        "       [  1.05315263e-02,   6.82972615e-01,   3.06495859e-01],\n",
        "       [  1.12165998e-03,   1.42997140e-01,   8.55881200e-01],\n",
        "       [  3.91669849e-02,   9.08085014e-01,   5.27480009e-02],\n",
        "       [  2.63460991e-02,   8.57149750e-01,   1.16504150e-01],\n",
        "       [  9.81650553e-01,   1.80470105e-02,   3.02436449e-04],\n",
        "       [  1.95037093e-03,   2.06757171e-01,   7.91292458e-01],\n",
        "       [  2.85300328e-03,   2.94718478e-01,   7.02428518e-01],\n",
        "       [  9.73906765e-01,   2.57134741e-02,   3.79761436e-04],\n",
        "       [  9.77680056e-03,   6.57652869e-01,   3.32570331e-01],\n",
        "       [  1.23660448e-01,   8.57060403e-01,   1.92791485e-02],\n",
        "       [  9.74868923e-01,   2.47331019e-02,   3.97974706e-04],\n",
        "       [  8.37793077e-04,   1.27781435e-01,   8.71380772e-01],\n",
        "       [  9.70042738e-01,   2.95051740e-02,   4.52088293e-04],\n",
        "       [  2.20340840e-03,   2.72862305e-01,   7.24934286e-01],\n",
        "       [  2.27953579e-02,   8.37040639e-01,   1.40164003e-01],\n",
        "       [  9.86169022e-01,   1.35858474e-02,   2.45130396e-04],\n",
        "       [  1.76390335e-02,   8.35974928e-01,   1.46386039e-01],\n",
        "       [  9.66990980e-01,   3.25469391e-02,   4.62080750e-04],\n",
        "       [  1.34258679e-03,   1.65595673e-01,   8.33061740e-01],\n",
        "       [  5.40931275e-04,   9.19016050e-02,   9.07557464e-01],\n",
        "       [  9.77650963e-01,   2.20001286e-02,   3.48907943e-04],\n",
        "       [  2.23832637e-03,   2.64416583e-01,   7.33345090e-01],\n",
        "       [  7.46312774e-04,   1.17182571e-01,   8.82071117e-01]])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calculate accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.predict_classes(X_te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50/50 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 2, 1, 2,\n",
        "       0, 2, 1, 0, 1, 2, 1, 1, 0, 2, 2, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2,\n",
        "       2, 0, 2, 2])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.mean(model.predict_classes(X_te) == y_te)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50/50 [==============================] - 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Text classification with Recurrent Neural Networks\n",
      "\n",
      "Instead of extracting features from text such as character or word ngrams, we can feed the text sequentially to a recurrent neural network and tell it what each text should be labeled as. The network will learn useful features automatically and encode them in its hidden layer. The particular type of recurrent neural network we'll use here has Long Short-Term Memory units."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.datasets as datasets "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = ['alt.atheism','talk.religion.misc','comp.graphics','sci.space']\n",
      "remove = ('headers', 'footers', 'quotes')\n",
      "data_train = datasets.fetch_20newsgroups(subset='train', categories=categories,\n",
      "                                shuffle=True, random_state=42,\n",
      "                                remove=remove)\n",
      "data_test = datasets.fetch_20newsgroups(subset='test', categories=categories,\n",
      "                               shuffle=True, random_state=42,\n",
      "                               remove=remove)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "def pad(x):\n",
      "    \"\"\"Pad 200 characters at the beginning of string.\"\"\"\n",
      "    return (\" \"*200) + x\n",
      "# Take first 200 characters of each post\n",
      "X_train = numpy.array([ [ ord(c) for c in pad(text)[:200] ] for text in data_train.data ])\n",
      "X_test  = numpy.array([ [ ord(c) for c in pad(text)[:200] ] for text in data_test.data ])\n",
      "\n",
      "# Convert the labels to one-hot encoding\n",
      "Y_train = OneHotEncoder().fit_transform(data_train.target.reshape((data_train.target.shape[0],1))).todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.models import Sequential\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers.recurrent import LSTM\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD, Adam\n",
      "\n",
      "max_features = 256              # number or unique characters (here bytes)\n",
      "maxlen = 200                    # maximum length of document\n",
      "model = Sequential()\n",
      "# Embedding with size 128\n",
      "model.add(Embedding(max_features, 128, input_length=maxlen))  \n",
      "# LSTM with state size 128\n",
      "model.add(LSTM(output_dim=128, activation='sigmoid', inner_activation='hard_sigmoid', return_sequences=False))\n",
      "model.add(Dense(4, activation='softmax'))\n",
      "optimizer =  Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
      "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Train the model for a number of iterations "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X_train, Y_train, batch_size=16, nb_epoch=10, verbose=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 1/10\n",
        "73s - loss: 1.4057\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "75s - loss: 1.3804\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "74s - loss: 1.3747\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "74s - loss: 1.3738\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "78s - loss: 1.3734\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "75s - loss: 1.3727\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "76s - loss: 1.3723\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "73s - loss: 1.3723\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "73s - loss: 1.3719\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "73s - loss: 1.3722\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "<keras.callbacks.History at 0x7f49ac1be6d0>"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predict classes and measure error rate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Y_test_pred = model.predict_classes(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 128/1353 [=>............................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 256/1353 [====>.........................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 384/1353 [=======>......................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 512/1353 [==========>...................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 640/1353 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 768/1353 [================>.............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        " 896/1353 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        "1024/1353 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        "1152/1353 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        "1280/1353 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
        "1353/1353 [==============================] - 9s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numpy.mean(Y_test_pred != data_test.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 117,
       "text": [
        "0.70879526977087948"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}