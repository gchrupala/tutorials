{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Theano\n",
      "\n",
      "- Embedded language within Python\n",
      "- Symbolic computations\n",
      "- Define a graph of symbolic variables\n",
      "- Compile to executable code\n",
      "- Execute"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Advantages\n",
      "\n",
      "- Compile to \n",
      "\n",
      "  - C\n",
      "  - CUDA\n",
      "  \n",
      "- Execute on\n",
      "\n",
      "  - CPU (multicore parellism)\n",
      "  - GPU\n",
      "  \n",
      "- Symbolic differentiation\n",
      "\n",
      "  - Compute gradients for SGD automatically"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Disadvantages\n",
      "\n",
      "- Symbolic \n",
      "\n",
      "  - additional layer of indirection\n",
      "  - impenetrable error messages\n",
      "  - limitations on available operators and control structures"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Basic examples\n",
      "## Sum of two scalars"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano.tensor as T\n",
      "\n",
      "a = T.scalar(dtype='float32')\n",
      "b = T.scalar(dtype='float32')\n",
      "c = a + b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have defined a graph of symbolic variables of the form ``c = a + b``"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "Elemwise{add,no_inplace}.0"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to compile and execute this code we can use the theano function ``function``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano import function\n",
      "\n",
      "add = function([a, b], c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<theano.compile.function_module.Function at 0x7f537a073810>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "``add`` is now a Python function which can add two scalars."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "add(2.0, 3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array(5.0, dtype=float32)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Mean Squared Error\n",
      "\n",
      "- Theano is most useful for computations on multidimensional arrays.\n",
      "- Let's compute the mean squared error between two vectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u = T.vector(dtype='float64')\n",
      "v = T.vector(dtype='float64')\n",
      "w = T.mean((u - v)**2)\n",
      "\n",
      "mse = function([u,v], w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "\n",
      "mse(numpy.array([1.0, 3.0], dtype='float64'), \n",
      "    numpy.array([3.0, 1.0], dtype='float64'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array(4.0)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lists will be automatically converted to numpy arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mse([1.0,3.0], [3.0, 1.0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array(4.0)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Linear regression with SGD"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from theano import shared\n",
      "\n",
      "class LinearRegression():\n",
      "    def __init__(self, size=2):\n",
      "        \n",
      "        X = T.matrix()  # input\n",
      "        y = T.vector()  # output\n",
      "        \n",
      "        W = shared(numpy.zeros(size))  # coefficients\n",
      "        b = shared(0.0) # intercept\n",
      "        eta = T.scalar() # learning rate\n",
      "        \n",
      "        y_hat = T.dot(X, W) + b        # predictions\n",
      "        error = T.mean((y_hat - y)**2) # errors\n",
      "        \n",
      "        gW, gb = T.grad(error, [W, b]) # gradients\n",
      "        \n",
      "        updates =  [(W, W - eta * gW),  # how to update the coefcients and intercept\n",
      "                    (b, b - eta * gb) ]\n",
      "\n",
      "        # Compile methods to train, predict, and return coeffs\n",
      "        self._train = function([X, y, eta], error, updates=updates)\n",
      "        self._predict = function([X], y_hat)\n",
      "        self._params = function([], [W, b])\n",
      "        \n",
      "    def train(self, X, y, eta=0.1, epochs=10):\n",
      "        for i in range(1, epochs):\n",
      "            error = self._train(X, y, eta)\n",
      "            print \"{0} {1}\".format(i, error)\n",
      "            \n",
      "    def predict(self, X):\n",
      "        return self._predict(X)\n",
      "    \n",
      "    def params(self):\n",
      "        return self._params() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = numpy.array(data.data[:,0:2], dtype='float32')\n",
      "y = numpy.array(data.data[:,2], dtype='float32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.train(X, y, eta=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 17.2199998946\n",
        "2 2.29027405019\n",
        "3 2.11950334212\n",
        "4 2.09639645049\n",
        "5 2.07504313804\n",
        "6 2.05398272255\n",
        "7 2.03319702471\n",
        "8 2.01268231674\n",
        "9 1.99243506143\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.predict(X[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([ 3.49527759,  3.30705352,  3.22271277,  3.15086148,  3.45310733,\n",
        "        3.72567218,  3.19538304,  3.42342634,  3.00715898,  3.32189402])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[array([ 0.57010809,  0.1484051 ]), array(0.06830849614779255)]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Theano for neural networks\n",
      "\n",
      "- NN models follow the same template\n",
      "\n",
      "  - Define outputs as a function of inputs\n",
      "  - Define weight updates as a function of error gradients\n",
      "  - The rest are details\n",
      "  \n",
      "   - Tune error rate\n",
      "   - Add momentum\n",
      "   - Implement other SGD variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Alternatives\n",
      "\n",
      "- Caffe http://caffe.berkeleyvision.org/\n",
      "- Torch http://torch.ch/docs/cvpr15.html\n",
      "- Tensorflow http://www.tensorflow.org/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Theano-based libraries\n",
      "\n",
      "- Built on top of Theano\n",
      "- Implement common models\n",
      "- Theanets - feedforward and recurrent networks\n",
      "  - http://theanets.readthedocs.org/\n",
      "- Passage - recurrent networks (seems abandoned)\n",
      "  - https://github.com/IndicoDataSolutions/Passage\n",
      "- Keras\n",
      "  - https://github.com/fchollet/keras\n",
      "- funktional (minimal wrapper)\n",
      "  - https://github.com/gchrupala/funktional\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Network architectures\n",
      "\n",
      "Theano makes it quite easy to define custom architectures, for example:\n",
      "\n",
      "![](files/img/multi.png)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}